# ==================================================
# Bone Fracture Prediction (Using Transfer Learning)
# ==================================================

# STEP 1: Import Libraries
import os
import zipfile
import numpy as np
import tensorflow as tf
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras import layers, models, callbacks
from tensorflow.keras.applications import EfficientNetB0
from tensorflow.keras.applications.efficientnet import preprocess_input
import matplotlib.pyplot as plt
from sklearn.metrics import classification_report, confusion_matrix
from google.colab import files

# STEP 2: Upload ZIP file
print(" Please upload your dataset ZIP file (must contain train/, val/, test/ folders).")
uploaded = files.upload()

# Get uploaded filename
zip_filename = next(iter(uploaded)) # Get the actual name of the uploaded file
# zip_filename = "bone.zip" # This line was causing the issue by hardcoding the filename
data_dir = "/content/bone"

# Unzip contents
with zipfile.ZipFile(zip_filename, 'r') as zip_ref:
    zip_ref.extractall(data_dir)

print("Dataset extracted successfully!")

# STEP 3: Define paths
train_dir = os.path.join(data_dir, "train")
val_dir   = os.path.join(data_dir, "val")
test_dir  = os.path.join(data_dir, "test")

# STEP 4: Preprocessing & Data Augmentation
img_height, img_width = 224, 224
batch_size = 32

train_datagen = ImageDataGenerator(
    preprocessing_function=preprocess_input,
    rotation_range=20,
    width_shift_range=0.2,
    height_shift_range=0.2,
    horizontal_flip=True,
    zoom_range=0.2
)

val_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)
test_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)

train_generator = train_datagen.flow_from_directory(
    train_dir,
    target_size=(img_height, img_width),
    batch_size=batch_size,
    class_mode="binary"
)

val_generator = val_datagen.flow_from_directory(
    val_dir,
    target_size=(img_height, img_width),
    batch_size=batch_size,
    class_mode="binary"
)

test_generator = test_datagen.flow_from_directory(
    test_dir,
    target_size=(img_height, img_width),
    batch_size=batch_size,
    class_mode="binary",
    shuffle=False
)

# STEP 5: Build Transfer Learning Model (EfficientNet)
base_model = EfficientNetB0(weights="imagenet", include_top=False, input_shape=(img_height, img_width, 3))
base_model.trainable = False  # Freeze base layers

model = models.Sequential([
    base_model,
    layers.GlobalAveragePooling2D(),
    layers.Dense(256, activation="relu"),
    layers.Dropout(0.4),
    layers.Dense(1, activation="sigmoid")
])

model.compile(
    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),
    loss="binary_crossentropy",
    metrics=["accuracy"]
)

model.summary()

# STEP 6: Callbacks for better training
checkpoint_cb = callbacks.ModelCheckpoint("best_fracture_model.h5", save_best_only=True, monitor="val_accuracy", mode="max")
earlystop_cb = callbacks.EarlyStopping(monitor="val_accuracy", patience=6, restore_best_weights=True)
reduce_lr_cb = callbacks.ReduceLROnPlateau(monitor="val_loss", factor=0.3, patience=3, verbose=1)

# STEP 7: Train the model
history = model.fit(
    train_generator,
    validation_data=val_generator,
    epochs=20,
    callbacks=[checkpoint_cb, earlystop_cb, reduce_lr_cb]
)

# STEP 8: Plot performance
plt.figure(figsize=(10,4))
plt.subplot(1,2,1)
plt.plot(history.history['accuracy'], label='Train Acc')
plt.plot(history.history['val_accuracy'], label='Val Acc')
plt.legend(); plt.title('Model Accuracy')

plt.subplot(1,2,2)
plt.plot(history.history['loss'], label='Train Loss')
plt.plot(history.history['val_loss'], label='Val Loss')
plt.legend(); plt.title('Model Loss')
plt.show()

# STEP 9: Evaluate on test set
test_loss, test_acc = model.evaluate(test_generator)
print(f" Test Accuracy: {test_acc:.4f}")

# STEP 10: Classification report and confusion matrix
test_generator.reset()
preds = model.predict(test_generator)
y_pred = (preds > 0.5).astype(int)
y_true = test_generator.classes

print("\nClassification Report:\n", classification_report(y_true, y_pred, target_names=list(test_generator.class_indices.keys())))
print("\nConfusion Matrix:\n", confusion_matrix(y_true, y_pred))

# STEP 11: Predict on a single random image
import random
import cv2

test_classes = [d for d in os.listdir(test_dir) if os.path.isdir(os.path.join(test_dir, d))]
test_class = random.choice(test_classes)
test_image_path = os.path.join(test_dir, test_class, random.choice(os.listdir(os.path.join(test_dir, test_class))))

img = tf.keras.preprocessing.image.load_img(test_image_path, target_size=(img_height, img_width))
img_array = tf.keras.preprocessing.image.img_to_array(img)
img_array = preprocess_input(img_array)
plt.imshow(img)
plt.axis('off')
plt.title(" Sample Test Image")
plt.show()

prediction = model.predict(np.expand_dims(img_array, axis=0))
pred_label = "Å¸w Fractured" if prediction[0][0] > 0.5 else " Normal"
confidence = prediction[0][0] if prediction[0][0] > 0.5 else 1 - prediction[0][0]
print(f" Predicted Label: {pred_label} (Confidence: {confidence*100:.2f}%)")


# ============================================================
# USER INPUT IMAGE PREDICTION (FINAL & FIXED VERSION)
# ============================================================

from google.colab import files
from tensorflow.keras.preprocessing import image
import numpy as np
import matplotlib.pyplot as plt

print("ğŸ“Œ Upload an X-ray image to predict (JPG/PNG):")
uploaded = files.upload()

for img_name in uploaded.keys():

    # Load & resize image
    img_path = img_name
    img = tf.keras.preprocessing.image.load_img(img_path, target_size=(img_height, img_width))
    img_array = tf.keras.preprocessing.image.img_to_array(img)

    # Preprocess using EfficientNet
    img_array = preprocess_input(img_array)
    img_array = np.expand_dims(img_array, axis=0)

    # Model prediction (0 = fractured, 1 = normal)
    prediction = model.predict(img_array)[0][0]

    #  FIXED LABEL MAPPING
    if prediction > 0.5:
        label = "âœ… Normal"
        confidence = prediction * 100
    else:
        label = "ğŸ¦´ Fractured"
        confidence = (1 - prediction) * 100

    # Show image
    plt.imshow(tf.keras.preprocessing.image.load_img(img_path))
    plt.axis('off')
    plt.title("ğŸ” Uploaded Image")
    plt.show()

    # Final Output
    print("\n==============================")
    print(f"ğŸ§  PREDICTION: {label}")
    print(f"ğŸ“Š CONFIDENCE: {confidence:.2f}%")
    print("==============================\n")
